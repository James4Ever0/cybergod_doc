{
    "summary": "The code defines classes `EntropyCalculator` and `ContentEntropyCalculator` to calculate entropy of categorical data using context managers, histograms, and compares results for different test cases.",
    "details": [
        {
            "comment": "The code defines a class `EntropyCalculator` that calculates the entropy of categorical data and a subclass `ContentEntropyCalculator` for calculating content entropy. The `EntropyCalculator` has methods to count categories, and the `ContentEntropyCalculator` extends this by counting bytes in content data. Both classes use numpy and scipy for efficient calculations.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/basic_interactive_program_emulation_and_image_with_docker_support/entropy_utils.py\":0-38",
            "content": "from contextlib import contextmanager\nimport numpy as np\nfrom scipy.stats import entropy\nclass EntropyCalculator:\n    def __init__(self, base=2):\n        self.cats_to_count = {}\n        self.base = base\n    def count(self, elem):\n        self._count(elem)\n    def _count(self, elem):\n        self.cats_to_count[elem] = self.cats_to_count.get(elem, 0) + 1\n    @property\n    def entropy(self):\n        vals = list(self.cats_to_count.values())\n        if vals != []:\n            hist = np.array(vals)\n            total_count = sum(hist)\n            hist = hist / total_count\n        else:\n            hist = []\n        ent = entropy(hist, base=self.base)\n        return ent\nclass ContentEntropyCalculator(EntropyCalculator):\n    def count(self, content):\n        if isinstance(content, str):\n            content = content.encode()\n        if not isinstance(content, bytes):\n            raise Exception(\"unknown content type:\", type(content))\n        content_int_arr = list(content)\n        for i in content_int_arr:\n            self."
        },
        {
            "comment": "This code defines a function `calculate_content_entropy` that calculates the entropy of content data. It uses a context manager `entropyContext` to create an instance of either `ContentEntropyCalculator` or `EntropyCalculator` based on whether the input is content or not. The function then counts the occurrences of different values in the content using histograms and returns the entropy value.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/basic_interactive_program_emulation_and_image_with_docker_support/entropy_utils.py\":38-77",
            "content": "_count(i)\n@contextmanager\ndef entropyContext(is_content=False):\n    if is_content:\n        calc = ContentEntropyCalculator()\n    else:\n        calc = EntropyCalculator()\n    try:\n        yield calc\n    finally:\n        del calc\ndef calculate_content_entropy(content):\n    with entropyContext(is_content=True) as calc:\n        calc.count(content)\n        return calc.entropy\n# def calculate_content_entropy(content, full=False):\n# if isinstance(content, str):\n#     content = content.encode()\n# if not isinstance(content,bytes):\n#     raise Exception(\"unknown content type:\", type(content))\n# content_int_arr = list(content)\n# if full:\n#     # use 256-1 bins\n#     hist, _ = np.histogram(content_int_arr, bins=255, range=(0,255))\n# else:\n#     cats = list(set(content_int_arr))\n#     cat_to_index = {cat:i for i, cat in enumerate(cats)}\n#     hist = np.zeros(len(cats))\n#     for elem in content_int_arr:\n#         index = cat_to_index[elem]\n#         hist[index] += 1\n# # normalize histogram.\n# hist = hist.astype(float)\n# norm_hist "
        },
        {
            "comment": "This code calculates the entropy of different test cases and prints the results. The more characters in the test case, the higher the entropy.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/basic_interactive_program_emulation_and_image_with_docker_support/entropy_utils.py\":77-96",
            "content": "= hist/len(content_int_arr)\n# # print('normalized histogram:', norm_hist)\n# ent = entropy(norm_hist, base=2)\n# return ent\nif __name__ == \"__main__\":\n    testcases = [\"aa\", \"ab\", \"abcdesd\", \"def\", \"hijklmn\", bytes(range(256))]\n    # the more chars the more entropy.\n    for case in testcases:\n        ent = calculate_content_entropy(case)\n        # ent_full = calculate_content_entropy(case, full=True)\n        print(\"testcase:\", case)\n        # identical!\n        print(\"entropy:\", ent)\n        # print(\"local entropy:\", ent)\n        # print(\"global entropy:\", ent_full)\n        print()"
        }
    ]
}