{
    "summary": "The code imports necessary modules, sets up logging and functions for model training and data processing. It includes strategies from hypothesis library, tests data fetching and loading models, evaluates CustomModel using Adam optimizer and SequentialTrainingQueue, and converts tensor to ConsciousFlow object for real-world application.",
    "details": [
        {
            "comment": "The code is importing various modules and classes from different files. It uses \"--log-level\" in pytest, references a link for potential compatibility issues, imports necessary libraries like torch and numpy, appends the path of a specific file to the system path, and imports functions and classes for model training and data processing. Finally, it imports strategies and settings from hypothesis library and stops the execution if needed using stopit.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":0-36",
            "content": "# use \"--log-level\" in pytest.\n# with this limited model structure, you may not find it \"evolving\".\n# you must let the AI design itself, evolve on its own.\n# shall you use pydantic v1 (>=1.10) or be incompatible with hypothesis.\n# ref: https://github.com/explosion/spaCy/issues/12659\n# lower the version of typing_extensions\nimport sys\nimport numpy as np\nsys.path.append(\"../\")\nfrom log_utils import logger_print\nimport torch\nfrom conscious_struct import (\n    trainModelWithDataBasePath,\n    Trainer,\n    SequentialTrainingQueue,\n    CustomModel,\n    ConsciousFlow,  # consists of `ConsciousBlock`\n    ConsciousBlock,\n    ConsciousStream,  # newly created wrapper!\n    HIDAction,\n    ConsciousBase,\n    KeyPress, KeyRelease, MouseMove, MouseScroll, MouseClick\n)\nfrom recording_train_parse import getTrainingData\nimport datetime\nimport pytest\nimport os\nfrom pathlib import Path\nfrom torchvision.models import VisionTransformer\nfrom hypothesis import given, settings\nfrom hypothesis.strategies import integers\nimport stopit\nimport ei"
        },
        {
            "comment": "This code appears to be a Python module that sets up logging for the test project. It imports necessary modules, configures the logging level and handlers, and starts logging with a timestamp and header. There is also a placeholder for a function called \"auto_teardown,\" but it does not appear to be implemented or used in this code snippet.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":36-77",
            "content": "nops\n# import logging\n# import log_utils\n# it is been commented out.\n# from typing import Generator, Union, AsyncGenerator\n# try:\n#     from typing import AwaitableGenerator\n# except:\n#     from typing_extensions import AwaitableGenerator\n# may log to other places.\n# infinite append.\n# from logging import StreamHandler\n# stdout_handler = StreamHandler(sys.stdout)\n# logging.basicConfig(\n#     # filename=filename,\n#     level=logging.getLogger().getEffectiveLevel(),\n#     # stream=sys.stderr,\n#     force=True,\n#     handlers=[myHandler, stdout_handler],\n# )\n# logging.basicConfig(level=logging.DEBUG, stream=sys.stdout, force=True)\n# logging.critical(\"\")\ncurrent_time = datetime.datetime.now().isoformat()\nlogger_print(f\"logging starts: {current_time}\".center(100, \"=\"))\n# logging.critical(\"\")\n# TODO: modify function at source code level, not here!\n# def auto_teardown(func):\n#     def inner_func(*args, **kwargs):\n#         val = func(*args, **kwargs)\n#         if not isinstance(val, Union[Generator, AsyncGenerator, Await"
        },
        {
            "comment": "Code tests fetching training data and loading model path.\n\nThis code contains two test functions, `test_get_training_data` and `test_fetching_training_data`, which are used to verify the functionality of fetching training data and loading the model path, respectively. \n\nThe `test_get_training_data` function iterates over each training DataFrame obtained from the `getTrainingData` function and prints out a log message for each one. This is intended to test the correctness and completeness of the training DataFrames returned by `getTrainingData`.\n\nThe `test_fetching_training_data` function imports two other functions, `trainModelWithDataBasePath` and `TestEnqueue`, from the `conscious_struct` module. It then creates an instance of a fake sequential queue called `myQueue` using the `TestEnqueue` class. \n\nThe function calls the `trainModelWithDataBasePath` function, passing in the `basePath` and the `myQueue` object as arguments. This is to test the functionality of training a model with data from a specific base path and a fake queue. If the model weight file does not exist at the specified path, an exception will be raised.\n\nThe code also defines a fixture called `basePath` that returns a string representing the base path for tests to use. It also has another fixture called `vit_model_path` which returns the path to the pre-trained model weight file (`vit_b_16-c867db91.pth`). If the file does not exist, an exception will be raised.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":77-116",
            "content": "ableGenerator]):\n#             yield val\n#             del val\n#         return val\n#     return inner_func\n@pytest.fixture(scope=\"session\")\ndef basePath():\n    return \"../recordings/2023-06-02T07_59_45.711256/\"\ndef test_get_training_data(basePath: str):\n    for trainingDataFrame in getTrainingData(basePath):\n        logger_print(\"training data frame:\", trainingDataFrame)\n# test fetching training data.\ndef test_fetching_training_data(basePath: str):\n    from conscious_struct import trainModelWithDataBasePath, TestEnqueue\n    myQueue = TestEnqueue()\n    # fake sequentialqueue.\n    trainModelWithDataBasePath(basePath, myQueue)\n@pytest.fixture(scope=\"session\")\ndef vit_model_path():\n    path = Path(\n        os.path.abspath(\n            relpath := \"../../../model_cache/vit_b_16-c867db91.pth\")\n    )\n    if not path.exists():\n        raise Exception(\n            f\"Current directory: {os.curdir}\\nModel weight does not exist: {path}\"\n        )\n    # return \"/Volumes/Toshiba XG3/model_cache/vit_b_16-c867db91.pth\"\n    retur"
        },
        {
            "comment": "Code snippet is defining several fixtures for use in tests.\n\n1. `vit_model` fixture loads a pre-trained VisionTransformer model and yields it for testing.\n2. `model` fixture instantiates a custom model based on the preloaded VisionTransformer model and yields it.\n3. `loss_fn` fixture sets up a CrossEntropyLoss object and yields it.\n\nThese fixtures can be used to test various aspects of the model, loss function, and other components in tests.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":116-163",
            "content": "n path\n@pytest.fixture(scope=\"session\")\ndef vit_model(vit_model_path: str):\n    import torchvision\n    # code from OA bot\n    # return torchvision.models.vit_b_16(pretrained=True)\n    vmodel = torchvision.models.vit_b_16()\n    # breakpoint()\n    mStateDict = torch.load(vit_model_path)\n    vmodel.load_state_dict(mStateDict)\n    yield vmodel\n    del vmodel\n@pytest.fixture(scope=\"session\")\ndef model(vit_model: VisionTransformer):\n    model = CustomModel(vit_model)\n    yield model\n    del model\n# def pretrained_model_path():\n#     path = ...\n#     return path\n# @pytest.fixture(scope='session')\n# def model_pretrained(model:CustomModel,pretrained_model_path:str):\n#     model.load_state_dict(torch.load(pretrained_model_path))\n#     yield model\n#     del model\n# you don't need the model to be trained at all to act.\n@pytest.fixture(scope=\"session\")\ndef loss_fn():\n    from torch.nn import CrossEntropyLoss\n    loss = CrossEntropyLoss(reduction=\"mean\")\n    yield loss\n    del loss\n@pytest.fixture(scope=\"session\")\ndef optimizer(mod"
        },
        {
            "comment": "Code is defining a test function that trains a CustomModel with training data and uses an Adam optimizer. The test function takes in a model, loss function, optimizer, base path, and random seed as parameters. It creates a Trainer object with the given model, loss function, and optimizer. Then it creates a SequentialTrainingQueue object that passes data to the trainer for training. The timeout exception handling is not implemented yet.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":163-194",
            "content": "el: CustomModel):\n    from torch.optim import Adam\n    lr = 0.00001\n    opt = Adam(model.parameters(), lr=lr)\n    yield opt\n    del opt\n# from hypothesis import HealthCheck\n@given(random_seed=integers())\n# @settings(suppress_health_check=(HealthCheck.function_scoped_fixture,),max_examples = 10, deadline=None)\n@settings(deadline=None, max_examples=2)\ndef test_train_model_with_training_data(\n    model: CustomModel, loss_fn, optimizer, basePath: str, random_seed: int\n):\n    # TODO: annotate our code with \"nptyping\" & \"torchtyping\" | \"jaxtyping\"\n    # TODO: haskell? functional python?\n    # (variadic types) ref: https://peps.python.org/pep-0646/\n    # use sympy for symbolic checks?\n    context_length = 2\n    batch_size = 1\n    myTrainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer)\n    myQueue = SequentialTrainingQueue(\n        context_length=context_length, batch_size=batch_size, trainer=myTrainer\n    )\n    # TODO: allow timeout exception to be raised, disallow any other exceptions.\n    # you migh"
        },
        {
            "comment": "The code snippet is testing the evaluation of a model by performing various HID (Human Input Device) actions, such as mouse clicks, mouse moves, and key presses/releases. It also includes threading timeout to shuffle the order of actions for testing purposes.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":194-223",
            "content": "t want to shuffle its order, for testing.\n    with stopit.ThreadingTimeout(5):  # timeout exception suppressed!\n        trainModelWithDataBasePath(\n            basePath, myQueue, shuffle_for_test=True, random_seed=random_seed\n        )\n    logger_print(\"SESSION TIMEOUT NOW\".center(60, \"_\"))\n@pytest.mark.parametrize(\n    \"HIDActionObj\",\n    [\n        MouseClick(x=993, y=659, button=\"Button.left\", pressed=True),\n        MouseMove(x=10, y=20),\n        MouseScroll(x=10, y=10, dx=10, dy=-10),\n        KeyPress(key=\"\"\"'9'\"\"\"),\n        KeyRelease(key=\"\"\"'8'\"\"\"),\n    ],\n)\ndef test_eval_with_model(model: CustomModel, HIDActionObj):\n    model.eval()\n    # it is been observed by video recording script.\n    max_x, max_y = 1280, 768\n    HIDActionJson = HIDActionObj.to_list()\n    # HIDActionJsonList = [HIDActionObj.to_list() for HIDActionObj in HIDActionObjList]\n    actionData = HIDAction.from_action_json(\n        HIDActionJson, max_x=max_x, max_y=max_y\n    ).to_ndarray()\n    # actionDataList = [HIDAction.from_action_json(\n  "
        },
        {
            "comment": "Creating random image data and ConsciousBlocks for a ConsciousFlow.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":223-242",
            "content": "  #     HIDActionJson, max_x=max_x, max_y=max_y\n    # ).to_ndarray() for HIDActionJson in HIDActionJsonList]\n    randomImageData = np.random.random(\n        (ConsciousBase.image_channels, ConsciousBase.image_dim, ConsciousBase.image_dim)\n    )\n    # imageData = einops.pack(randomImageData, \"*\")  # just what shape shall this be?\n    imageData = einops.rearrange(randomImageData, \"c h w -> (c h w)\")\n    # actionConsciousBlocks = [ConsciousBlock(\n    #     data_type=\"HIDAction\", special_token=None, action_data=actionData\n    # ) for actionData in actionDataList]\n    actionConsciousBlock = ConsciousBlock(\n        data_type=\"HIDAction\", special_token=None, action_data=actionData\n    )\n    imageConsciousBlock = ConsciousBlock(\n        data_type=\"image\", special_token=None, image_data=imageData\n    )\n    # cs = ConsciousFlow(consciousBlocks=[*actionConsciousBlocks, imageConsciousBlock])\n    # cf = ConsciousFlow(consciousBlocks=[ # not here but inside.\n    #     actionConsciousBlock,\n    #     # imageConsciousBlo"
        },
        {
            "comment": "Creating ConsciousFlow objects for action and image, then creating a ConsciousStream with both conscious flows. Finally, forward pass of the model using the new conscious stream. Printing the result and its shape.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":242-264",
            "content": "ck,\n    #     ]\n    # )\n    cf = ConsciousFlow(\n        consciousBlocks=[actionConsciousBlock, imageConsciousBlock])\n    # must be 3d, not 2d.\n    # print(actionConsciousBlock.to_tensor().shape) # torch.Size([154639]) ~ d\n    # print(imageConsciousBlock.to_tensor().shape) # torch.Size([154639]) ~ d\n    # print(cf.to_tensor().shape) # torch.Size([2, 154639]) ~ s d\n    # breakpoint()\n    # result = model.forward(conscious_stream = cf.to_tensor()) # instead of this.\n    # we do this:\n    cs = ConsciousStream(consciousFlows=[cf])\n    result = model.forward(conscious_stream=cs.to_tensor())\n    # result = model.forward(conscious_stream=einops.pack([cf.to_tensor()], \"* s d\")) # b s d\n    # do not load any weight yet. just use its random state.\n    # do not execute anything in this test! just get the predicted things out.\n    logger_print(\"printing result\")\n    # with gradient! shall be shape of (b (batch size), d (data length))\n    logger_print(result)\n    logger_print('result shape:', result.shape)  # torch.Siz"
        },
        {
            "comment": "Converting tensor to ConsciousFlow object, storing in cf_result, and logging the result for potential real-world application.",
            "location": "\"/media/root/Toshiba XG3/works/cybergod_doc/src/test/test_project.py\":264-270",
            "content": "e([1, 154639])\n    # now decode!\n    cf_result = ConsciousFlow.from_tensor(result.detach())\n    logger_print(\"decoded result:\", cf_result)\n    # consider running this stuff in real world."
        }
    ]
}