<!DOCTYPE html>
<html lang="en">

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="github-markdown.css">
    <style>
        .markdown-body {
            box-sizing: border-box;
            min-width: 200px;
            max-width: 980px;
            margin: 0 auto;
            padding: 45px;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }
        }
    </style>
</head>

<body>
    <article class="markdown-body">
<h2>Project Structure:</h2>
<ul>
<li><strong><code>agi_computer_control</code></strong> <em>Interactive AI, Docker, Machine Learning</em><ul>
<li><a href="index.html?q=/jinja_utils.py"><code>jinja_utils.py</code></a> <em>Jinja Python utility: import, manipulate, check, update, output.</em></li>
<li><a href="index.html?q=/recorder.py"><code>recorder.py</code></a> <em>Script records computer screen with sound and keystrokes.</em></li>
<li><strong><code>qstar_my_guess</code></strong> <em>Exploring A</em>, MCTS, and transformers for AI problem-solving.*<ul>
<li><a href="index.html?q=/qstar_my_guess/mcts_test.py"><code>mcts_test.py</code></a> <em>CartPole game, OpenLoopMCTS, 1000 iterations, non-training mode, saving failed.</em></li>
<li><a href="index.html?q=/qstar_my_guess/README.md"><code>README.md</code></a> <em>AI-powered code tagging, indexing, and writing. RAG-backed, acknowledging human uniqueness.</em></li>
<li><a href="index.html?q=/qstar_my_guess/mcts_pseudo.py"><code>mcts_pseudo.py</code></a> <em>Monte Carlo Tree Search Algorithm in Python</em></li>
<li><a href="index.html?q=/qstar_my_guess/main.py"><code>main.py</code></a> <em>Exploring MCTS, transformers, reward functions in PPO. Hidden latent space for video generation.</em></li>
<li><a href="index.html?q=/qstar_my_guess/signature_test.py"><code>signature_test.py</code></a> <em>Type hints and runtime checking with overload function.</em></li>
<li><a href="index.html?q=/qstar_my_guess/thought_tokens.py"><code>thought_tokens.py</code></a> <em>Thought token insertion code. Iterative, probabilistic.</em></li>
<li><a href="index.html?q=/qstar_my_guess/time_traversal.py"><code>time_traversal.py</code></a> <em>Monte Carlo Tree Search, gradient descent, world model updates, sequence manipulations, cosine similarity, computational time, loss delta.</em></li>
<li><a href="index.html?q=/qstar_my_guess/astar_test.py"><code>astar_test.py</code></a> <em>A</em> algorithm maze solver tested.*</li>
</ul>
</li>
<li><a href="index.html?q=/use_logging.py"><code>use_logging.py</code></a> <em>Various logging implementations with Python libraries.</em></li>
<li><a href="index.html?q=/player.py"><code>player.py</code></a> <em>Manage keyboard/mouse with Pynput, hotkeys. DPI-aware, event order maintenance, no "ctrl+/" support.</em></li>
<li><a href="index.html?q=/array_static_typecheck.py"><code>array_static_typecheck.py</code></a> <em>Static-typed array class with type checks, operations, and SymPy integration.</em></li>
<li><a href="index.html?q=/array_check_ast_parsing.py"><code>array_check_ast_parsing.py</code></a> <em>Python code parser for annotations.</em></li>
<li><a href="index.html?q=/hotkey_listener.py"><code>hotkey_listener.py</code></a> <em>Hotkey listener code with key functions, awaiting activation.</em></li>
<li><strong><code>the_cage_dataset</code></strong><ul>
<li><a href="index.html?q=/the_cage_dataset/README.md"><code>README.md</code></a> <em>Control bot with "cage", synch timestamps.</em></li>
</ul>
</li>
<li><a href="index.html?q=/README.md"><code>README.md</code></a> <em>Entertaining AI project with devcontainers and utility features.</em></li>
<li><strong><code>the_frozen_forest_intro</code></strong> <em>Multimodal training dataset "The Frozen Forest" introduction.</em><ul>
<li><a href="index.html?q=/the_frozen_forest_intro/test_dataset.py"><code>test_dataset.py</code></a> <em>Screenshot capturing Pygame window for typing words, AI dangers discussed.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/sample_browser_events.py"><code>sample_browser_events.py</code></a> <em>Browser event listeners for mouse and keyboard in Pydantic classes.</em></li>
<li><strong><code>keylogger_extension</code></strong> <em>Initializes and manages keylogger extension for frozen forest.</em><ul>
<li><strong><code>virtual-keylogger</code></strong> <em>Initializes server, handles errors, manages HID events for HDFC Bank's netbanking virtual keylogger.</em><ul>
<li><a href="index.html?q=/the_frozen_forest_intro/keylogger_extension/virtual-keylogger/webpack.config.js"><code>webpack.config.js</code></a> <em>Configuring webpack for production, entry: "./src/index.js", output: "main.js" in "dist".</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/keylogger_extension/virtual-keylogger/README.md"><code>README.md</code></a> <em>Virtual keylogger for HDFC Bank's netbanking</em></li>
<li><strong><code>src</code></strong><ul>
<li><a href="index.html?q=/the_frozen_forest_intro/keylogger_extension/virtual-keylogger/src/index.js"><code>index.js</code></a> <em>Initializes server, handles errors, and manages HID events.</em></li>
</ul>
</li>
</ul>
</li>
<li><a href="index.html?q=/the_frozen_forest_intro/keylogger_extension/init.cmd"><code>init.cmd</code></a> <em>Initiating keylogger download.</em></li>
</ul>
</li>
<li><a href="index.html?q=/the_frozen_forest_intro/random_browser_agent.py"><code>random_browser_agent.py</code></a> <em>Interacting with webpages, resolving mouse issues.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/take_viewport_screenshot.js"><code>take_viewport_screenshot.js</code></a> <em>Take viewport screenshot and open it in new tab.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/drissionpage_common.py"><code>drissionpage_common.py</code></a> <em>Configures Chromium browser with extensions for ad management and page object timeout.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/README.md"><code>README.md</code></a> <em>Introducing "The Frozen Forest" dataset for multimodal training.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/pw_listen_to_events.py"><code>pw_listen_to_events.py</code></a> <em>Browser extension event listening challenges with VS Code and Playwright.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/keylogger_server.py"><code>keylogger_server.py</code></a> <em>FastAPI server for event monitoring, logs errors, stores data in JSON.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/playwright_locate_mouse_viewport.py"><code>playwright_locate_mouse_viewport.py</code></a> <em>Automates mouse actions, screenshots Paint.js, checks image size.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/render_cursor_on_image.py"><code>render_cursor_on_image.py</code></a> <em>Cursor overlay on screen image.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/pw_random_actor.py"><code>pw_random_actor.py</code></a> <em>Random character, Playwright setup, Bilibili screenshots.</em></li>
<li><a href="index.html?q=/the_frozen_forest_intro/watch_video_in_webpage.py"><code>watch_video_in_webpage.py</code></a> <em>Webpage automation with AI-controlled browsers.</em></li>
</ul>
</li>
<li><a href="index.html?q=/Dockerfile"><code>Dockerfile</code></a> <em>Dockerfile: x11docker base, dev server setup</em></li>
<li><a href="index.html?q=/off_streaming_utils.sh"><code>off_streaming_utils.sh</code></a> <em>Terminates streaming_utils processes.</em></li>
<li><a href="index.html?q=/Makefile"><code>Makefile</code></a> <em>Automates project setup, builds, and tests.</em></li>
<li><strong><code>lego_mindstorm_physical_mouse_keyboard_control</code></strong> <em>Control LEGO EV3 with keyboard and mouse over USB</em><ul>
<li><a href="index.html?q=/lego_mindstorm_physical_mouse_keyboard_control/test.py"><code>test.py</code></a> <em>Init EV3 motor, play sound, define motor object, move 100 units.</em></li>
<li><a href="index.html?q=/lego_mindstorm_physical_mouse_keyboard_control/usb_ev3.py"><code>usb_ev3.py</code></a> <em>USB EV3 control script.</em></li>
<li><a href="index.html?q=/lego_mindstorm_physical_mouse_keyboard_control/README.md"><code>README.md</code></a> <em>Control bot with keyboard and mouse without detection or batteries.</em></li>
</ul>
</li>
<li><strong><code>basic_interactive_program_emulation_and_image_with_docker_support</code></strong> <em>Docker support, interactive emulation, image development</em><ul>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/timeout_utils.py"><code>timeout_utils.py</code></a> <em>Timeout and retry decorators for functions.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/beat_common.py"><code>beat_common.py</code></a> <em>Decorator function for caching, server info, GET requests, and timeout management.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/rerun_docker_daemon.py"><code>rerun_docker_daemon.py</code></a> <em>Manage Docker service, handle OS differences, fix Win11 hangs.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/entropy_utils.py"><code>entropy_utils.py</code></a> <em>Entropy calculation using classes and context managers.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/requirements.txt"><code>requirements.txt</code></a> <em>Project dependencies for cross-platform emulation with Docker support</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/beat_server.py"><code>beat_server.py</code></a> <em>FastAPI, timezone, roles, PIDs, UUIDs, HTTP requests, status management.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/get_pid_of_self.py"><code>get_pid_of_self.py</code></a> <em>Retrieves PID of self.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/naive_interactive.py"><code>naive_interactive.py</code></a> <em>Interactive loop with sleep and random word gen.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/to_be_killed.py"><code>to_be_killed.py</code></a> <em>Killable process ID printer.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/bytes_actor.py"><code>bytes_actor.py</code></a> <em>BytesActor: Docker-supported, NaiveActor-based interactive program.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/wexpect_example.py"><code>wexpect_example.py</code></a> <em>weexpect: cmd emulation via Python, Docker support.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/naive_actor.py"><code>naive_actor.py</code></a> <em>Naive actor benchmarks non-blocking actor performance with sockets and time measurement.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/README.md"><code>README.md</code></a> <em>Train and use a bot for exploration and learning.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/pyinstrument_profile.py"><code>pyinstrument_profile.py</code></a> <em>Profile long-running program with PyInstrument.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/sequence_learner.py"><code>sequence_learner.py</code></a> <em>Sequence learner predictor with Docker support.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/kill_server.py"><code>kill_server.py</code></a> <em>Manage client processes and communicate with server, monitoring status.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/metaheuristic_predictive_actor.py"><code>metaheuristic_predictive_actor.py</code></a> <em>Metaheuristic predictive actor class with kernel updates.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/pull_alpine_with_different_arch.py"><code>pull_alpine_with_different_arch.py</code></a> <em>Download Docker images of Alpine Linux with different arch support.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/type_utils.py"><code>type_utils.py</code></a> <em>Ensures input is bytes or string, raises exceptions if not.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/vocabulary.py"><code>vocabulary.py</code></a> <em>Vocab class, random ASCII/bytes strings.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/predictive_alpine_actor.py"><code>predictive_alpine_actor.py</code></a> <em>Predictive Alpine Actor with Docker Support</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/predictive_bytes_alpine_actor.py"><code>predictive_bytes_alpine_actor.py</code></a> <em>Predicts bytes with Docker support.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/loop_forever.py"><code>loop_forever.py</code></a> <em>Infinite loop, continuously increments 'a'.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/log_common.py"><code>log_common.py</code></a> <em>Rotating file logger, debug level, exceptions handling.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/profile_vis.py"><code>profile_vis.py</code></a> <em>Sorting profiling data by calls in "profile_vis.py"</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/alpine_actor.py"><code>alpine_actor.py</code></a> <em>Interactive Docker emulation with exceptions and logging.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/dependent_task_timeout_exec.py"><code>dependent_task_timeout_exec.py</code></a> <em>Timeout future execution.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/test_beat_server.py"><code>test_beat_server.py</code></a> <em>Test Beat Server with Unittest and Docker support.</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/alpine_bytes_actor.py"><code>alpine_bytes_actor.py</code></a> <em>AlpineBytesActor: Loop, Read-Write, Forever</em></li>
<li><a href="index.html?q=/basic_interactive_program_emulation_and_image_with_docker_support/Dockerfile"><code>Dockerfile</code></a> <em>Installs Docker from Alpine APT.</em></li>
</ul>
</li>
<li><strong><code>dynamic_plasticity_neural_networks</code></strong> <em>Dynamic neural networks with plasticity for adaptive bot decision-making.</em><ul>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/neural_evolution.py"><code>neural_evolution.py</code></a> <em>Neural evolution using NEAT from evotorch library.</em></li>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/sparse_matrix_multiplication.py"><code>sparse_matrix_multiplication.py</code></a> <em>Timing sparse matrix multiplication performance.</em></li>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/dnn_reference.py"><code>dnn_reference.py</code></a> <em>Sigmoid-based DNN classes and functions.</em></li>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/README.md"><code>README.md</code></a> <em>Dynamic neural networks with movable artificial neurons.</em></li>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/dynamic_neural_network.py"><code>dynamic_neural_network.py</code></a> <em>Dynamic neural network for bot decision-making</em></li>
<li><a href="index.html?q=/dynamic_plasticity_neural_networks/MCTS_NAS.md"><code>MCTS_NAS.md</code></a> <em>MCTS for NAS: Efficient Network Architecture Search.</em></li>
</ul>
</li>
<li><a href="index.html?q=/mydatamodel.py"><code>mydatamodel.py</code></a> <em>MyDataModel.py: Generates Python class from MyDataModel.yaml. Pydantic BaseModel.</em></li>
<li><strong><code>lunar_lander_test</code></strong><ul>
<li><a href="index.html?q=/lunar_lander_test/test.py"><code>test.py</code></a> <em>Lunar Lander test with Gymnasium, 1000 random actions.</em></li>
</ul>
</li>
<li><a href="index.html?q=/mouse-and-keyboard-encoding-fft.py"><code>mouse-and-keyboard-encoding-fft.py</code></a> <em>Fast Fourier Transform mouse encoding, neural networks, embeddings, and positional encodings.</em></li>
<li><a href="index.html?q=/terminal_test_tk.py"><code>terminal_test_tk.py</code></a> <em>Tkinter window with terminal widget.</em></li>
<li><a href="index.html?q=/recording_train_parse.py"><code>recording_train_parse.py</code></a> <em>Train data synchronization and processing.</em></li>
<li><a href="index.html?q=/pytropos_check.py"><code>pytropos_check.py</code></a> <em>Matrix multiplication with unit testing.</em></li>
<li><strong><code>containerized_chatgpt_agent</code></strong> <em>Containerized ChatGPT AI scripts</em><ul>
<li><a href="index.html?q=/containerized_chatgpt_agent/Dockerfile_autoexec_visual"><code>Dockerfile_autoexec_visual</code></a> <em>Dockerfile: Xfce4, Xvfb, screenshot, PyAutoGUI setup.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/Modelfile_visual"><code>Modelfile_visual</code></a> <em>Containerized ChatGPT, llama2-uncensored base, temperature 1, commands.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/ai_captialism.py"><code>ai_captialism.py</code></a> <em>Account handling, population limits, payments, incomplete pay formatter.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/ollama_utils.py"><code>ollama_utils.py</code></a> <em>Ollama token limits, context manager, response stream</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/visual_server_on_ubuntu.py"><code>visual_server_on_ubuntu.py</code></a> <em>Python script for visual server control on Ubuntu</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/visual_autoexec_example.py"><code>visual_autoexec_example.py</code></a> <em>Multi-agent system: ChatGPT, visual model, commands, errors.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/port_util.py"><code>port_util.py</code></a> <em>Set default port, parse args, validate custom port.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/Dockerfile"><code>Dockerfile</code></a> <em>Install pip, open-interpreter via Tsinghua mirror.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/Dockerfile_autoexec"><code>Dockerfile_autoexec</code></a> <em>Installs Python chat agent dependencies, copies scripts.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/container_autoexec_example.py"><code>container_autoexec_example.py</code></a> <em>Container AI agent script with LitEllm, command parsing, retries, sleep delay.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/are_you_kidding_me.txt"><code>are_you_kidding_me.txt</code></a> <em>Image processing and password cracking code, ASCII-PNG challenges.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/install_pip.sh"><code>install_pip.sh</code></a> <em>Install pip, check success or retry with apt-update.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/build_llama2_autoexec_model.sh"><code>build_llama2_autoexec_model.sh</code></a> <em>Automating LLaMA model creation in container.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/install_pip_and_pyautogui_prequisites.sh"><code>install_pip_and_pyautogui_prequisites.sh</code></a> <em>Install pip, PyAutoGUI, dependencies in container.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/change_icon_size.py"><code>change_icon_size.py</code></a> <em>Resize image while maintaining aspect ratio, save resized version.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/run_llama2.sh"><code>run_llama2.sh</code></a> <em>Dockerize and run Llama 2</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/visual_autoexec_main.sh"><code>visual_autoexec_main.sh</code></a> <em>Runs Xvfb, Ubuntu visual server, and example script.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/diff_utils.py"><code>diff_utils.py</code></a> <em>Diff utilities for comparing strings in Python</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/ptyproc.py"><code>ptyproc.py</code></a> <em>Containerized chat server with sound effects and adjustable settings.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/build_and_run_image.sh"><code>build_and_run_image.sh</code></a> <em>Dockerize ChatGPT agent, build and run.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/terminal_config.py"><code>terminal_config.py</code></a> <em>Configure terminal: 80 cols, 25 rows.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/Modelfile"><code>Modelfile</code></a> <em>Docker image, llama2 model, coherent AI chat in bash shell.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/README.md"><code>README.md</code></a> <em>Containerizing AI, GUI vs Terminal challenges, "Helen Keller" project</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/dna_like_transformation_triple_or_more_strands.py"><code>dna_like_transformation_triple_or_more_strands.py</code></a> <em>Bitwise DNA-like transformation with triple strands.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/test_image_to_ascii.py"><code>test_image_to_ascii.py</code></a> <em>Test image to ASCII converter</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/run_autogpt_in_container.sh"><code>run_autogpt_in_container.sh</code></a> <em>AutoGPT in Baidu Cloud container, GPT3-only.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/run_visual_autoexec.sh"><code>run_visual_autoexec.sh</code></a> <em>Start, clean, and run visual_autoexec containerized chatbot.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/run_autoexec.sh"><code>run_autoexec.sh</code></a> <em>Build and run Dockerized Python agent with scripts.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/build_llama2_visual_autoexec_model.sh"><code>build_llama2_visual_autoexec_model.sh</code></a> <em>Creating visual autoexec model file.</em></li>
<li><a href="index.html?q=/containerized_chatgpt_agent/startup_ollama_service.sh"><code>startup_ollama_service.sh</code></a> <em>Start Ollama container, create ChatGPT agent.</em></li>
</ul>
</li>
<li><strong><code>external_reference</code></strong> <em>External reference directory: Contains 4 GitHub repos for cloning.</em><ul>
<li><a href="index.html?q=/external_reference/extra_init.sh"><code>extra_init.sh</code></a> <em>Clones CogVLM and AppAgent repos.</em></li>
<li><a href="index.html?q=/external_reference/supercharge_init.sh"><code>supercharge_init.sh</code></a> <em>Supercharges GitHub repos: 4 clones.</em></li>
<li><a href="index.html?q=/external_reference/init.cmd"><code>init.cmd</code></a> <em>Init script for cloning repos.</em></li>
</ul>
</li>
<li><a href="index.html?q=/compose.yaml"><code>compose.yaml</code></a> <em>Compose VNC services with images</em></li>
<li><a href="index.html?q=/packup.sh"><code>packup.sh</code></a> <em>"Remove, change dir, archive, move file"</em></li>
<li><a href="index.html?q=/streaming_utils.yaml"><code>streaming_utils.yaml</code></a> <em>Windows with commands and directories configuration.</em></li>
<li><strong><code>propaganda</code></strong> <em>Step-by-step video creation and AI productivity scripts</em><ul>
<li><strong><code>cybergod_propaganda</code></strong><ul>
<li><a href="index.html?q=/propaganda/cybergod_propaganda/README.md"><code>README.md</code></a> <em>Cybergod propaganda: Step-by-step video creation.</em></li>
</ul>
</li>
<li><strong><code>video_script</code></strong> <em>Automated Cybergod AI videos for productivity and health.</em><ul>
<li><a href="index.html?q=/propaganda/video_script/clyde_script_cn.txt"><code>clyde_script_cn.txt</code></a> <em>Introducing Cybergod AI鼠标键控. Automate, save time. Developer collaboration encouraged.</em></li>
<li><a href="index.html?q=/propaganda/video_script/compile_script.py"><code>compile_script.py</code></a> <em>Background music location query in script</em></li>
<li><a href="index.html?q=/propaganda/video_script/download_video.py"><code>download_video.py</code></a> <em>Video script downloader and saver.</em></li>
<li><a href="index.html?q=/propaganda/video_script/clyde_script.txt"><code>clyde_script.txt</code></a> <em>Cybergod: AI controller, inspire developers.</em></li>
<li><a href="index.html?q=/propaganda/video_script/preprocess.py"><code>preprocess.py</code></a> <em>Script preprocesses, splits, and lists data for script.md.</em></li>
<li><a href="index.html?q=/propaganda/video_script/script.txt"><code>script.txt</code></a> <em>"Cybergod automates computer tasks, boosts productivity and health."</em></li>
<li><a href="index.html?q=/propaganda/video_script/read_text.py"><code>read_text.py</code></a> <em>Generate audio from text, YAML data.</em></li>
<li><a href="index.html?q=/propaganda/video_script/README.md"><code>README.md</code></a> <em>Search videos, API endpoint, ffmpeg conversion.</em></li>
<li><a href="index.html?q=/propaganda/video_script/script.yaml"><code>script.yaml</code></a> <em>"Cybergod YAML script with video link and text"</em></li>
</ul>
</li>
<li><strong><code>agi_computer_recordings</code></strong><ul>
<li><a href="index.html?q=/propaganda/agi_computer_recordings/launch_server.cmd"><code>launch_server.cmd</code></a> <em>Command connects to host and WebDAV path for recordings.</em></li>
</ul>
</li>
</ul>
</li>
<li><a href="index.html?q=/hotkey_tester.py"><code>hotkey_tester.py</code></a> <em>Control disables all hotkeys.</em></li>
<li><a href="index.html?q=/pyanalyze_check.py"><code>pyanalyze_check.py</code></a> <em>Analyze pytest lambda function serialization and extraction.</em></li>
<li><a href="index.html?q=/test_calculated_type.py"><code>test_calculated_type.py</code></a> <em>Unify PyTorch types with Erg static checking.</em></li>
<li><a href="index.html?q=/mypy_check.py"><code>mypy_check.py</code></a> <em>Mock-based API function verification. Class MyClass, age property, tensor function.</em></li>
<li><a href="index.html?q=/sync_utils.sh"><code>sync_utils.sh</code></a> <em>Sync script: Updates and copies files.</em></li>
<li><a href="index.html?q=/generate_datamodel_code.sh"><code>generate_datamodel_code.sh</code></a> <em>Generate Python code from YAML datamodel file: MyModel.</em></li>
<li><a href="index.html?q=/mydatamodel.yaml"><code>mydatamodel.yaml</code></a> <em>YAML data model, two sets of variables with letter-number pairs.</em></li>
<li><a href="index.html?q=/pytest_disable_assertion_inspection_use_better_exceptions.py"><code>pytest_disable_assertion_inspection_use_better_exceptions.py</code></a> <em>Replaces numpy.array with marray, sets test exceptions.</em></li>
<li><a href="index.html?q=/try_better_exceptions.sh"><code>try_better_exceptions.sh</code></a> <em>Improved exception handling script.</em></li>
<li><a href="index.html?q=/record_playback_test.py"><code>record_playback_test.py</code></a> <em>Record and playback Windows UI actions with pywinauto.</em></li>
<li><a href="index.html?q=/tsalib_test.py"><code>tsalib_test.py</code></a> <em>Test: Tsalib static shape checking in PyTorch.</em></li>
<li><a href="index.html?q=/hid_utils.py"><code>hid_utils.py</code></a> <em>Mouse and key input utilities. Translates, stores, writes.</em></li>
<li><a href="index.html?q=/render_python_code.py"><code>render_python_code.py</code></a> <em>Python code renderer with Jinja templates.</em></li>
<li><a href="index.html?q=/run_gpu_docker.sh"><code>run_gpu_docker.sh</code></a> <em>Test GPU access in Docker container.</em></li>
<li><a href="index.html?q=/try_better_exceptions.py"><code>try_better_exceptions.py</code></a> <em>Raises KeyError for non-existent key "2" in dictionary "a"</em></li>
<li><strong><code>action_state_machine</code></strong><ul>
<li><a href="index.html?q=/action_state_machine/example.txt"><code>example.txt</code></a> <em>Terminal session: user input, responses, prompts, cursor movements.</em></li>
</ul>
</li>
<li><strong><code>binary_program_synthesis_cpu_assembly_execution</code></strong> <em>Binary program synthesis and assembly execution without human interface.</em><ul>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/vkq_bin.py"><code>vkq_bin.py</code></a> <em>Binary quantization config, VKQAttention class for linear layers.</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/README.md"><code>README.md</code></a> <em>Evolutionary program synthesis and assembly execution without human interface.</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/interpret_and_save_binary_program.py"><code>interpret_and_save_binary_program.py</code></a> <em>Binary program interpretation and saving.</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/convert_binary_files_as_zero_and_one_streams.py"><code>convert_binary_files_as_zero_and_one_streams.py</code></a> <em>Binary file conversion to 8-bit streams.</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/softmax_test.py"><code>softmax_test.py</code></a> <em>Softmax test: 2D activation for random (2,3) tensor.</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/gpt-binary-training.py"><code>gpt-binary-training.py</code></a> <em>Trains GPT2 model to generate binary input</em></li>
<li><a href="index.html?q=/binary_program_synthesis_cpu_assembly_execution/bnn_data_ingest.py"><code>bnn_data_ingest.py</code></a> <em>Binary quantized tensor computation with attention.</em></li>
</ul>
</li>
<li><strong><code>directml_yolov5</code></strong> <em>DirectML-powered YOLOv5 inference tests</em><ul>
<li><a href="index.html?q=/directml_yolov5/test_nograd.py"><code>test_nograd.py</code></a> <em>YOLOv5 model, DirectML inference with warnings.</em></li>
<li><a href="index.html?q=/directml_yolov5/test_concat.py"><code>test_concat.py</code></a> <em>Concatenation test using directml &amp; torch</em></li>
<li><a href="index.html?q=/directml_yolov5/test.py"><code>test.py</code></a> <em>DirectML-enabled, zero-sized array handling inference mode code.</em></li>
</ul>
</li>
<li><a href="index.html?q=/random_actor.py"><code>random_actor.py</code></a> <em>Random mouse and keyboard inputs generator for simulation.</em></li>
<li><strong><code>hardware_capture_hid_power_control</code></strong> <em>Hardware capture, HID power control, Python scripts</em><ul>
<li><a href="index.html?q=/hardware_capture_hid_power_control/common_keycodes.py"><code>common_keycodes.py</code></a> <em>Translation of hardware keycodes for computer compatibility.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/parse_hid_keycodes.py"><code>parse_hid_keycodes.py</code></a> <em>Parse HID keycode data, pandas DataFrames, error handling, CSV/JSON output.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/README.md"><code>README.md</code></a> <em>Power control via <code>/dev/serial/by-id/*</code> with HID control using <code>hidapi</code>.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/multiple_inheritance.py"><code>multiple_inheritance.py</code></a> <em>Multiple inheritance confusion with MRO.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/test_control.py"><code>test_control.py</code></a> <em>Power control with HID protocol for mouse and keyboard.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/set_capture_card_properties.sh"><code>set_capture_card_properties.sh</code></a> <em>Installs packages, suggests OBS, sets video format &amp; fps with v4l2-ctl.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/Makefile"><code>Makefile</code></a> <em>Compiles and executes Python script with Makefile</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/test_hidraw.py"><code>test_hidraw.py</code></a> <em>Test HID USB device interaction code, adjustable paths.</em></li>
<li><a href="index.html?q=/hardware_capture_hid_power_control/test_video_capture.py"><code>test_video_capture.py</code></a> <em>Configure video device, save frames as images. Fails to work correctly.</em></li>
</ul>
</li>
<li><a href="index.html?q=/conscious_struct.py"><code>conscious_struct.py</code></a> <em>"Python code for image processing, LSTM training, and RNN input prep."</em></li>
<li><a href="index.html?q=/packup.cmd"><code>packup.cmd</code></a> <em>Archives, removes 7z, moves backup.</em></li>
<li><a href="index.html?q=/config.py"><code>config.py</code></a> <em>Sets timestep, defines state path.</em></li>
<li><a href="index.html?q=/install_nvidia_container_toolkit.sh"><code>install_nvidia_container_toolkit.sh</code></a> <em>NVIDIA container toolkit installer for Kali 2022.2.</em></li>
<li><strong><code>ubuntu_qemu_utm_arm_record</code></strong> <em>Ubuntu QEMU UTM ARM recording setup</em><ul>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/hdf5_test.py"><code>hdf5_test.py</code></a> <em>Create HDF5 file with boolean dataset "myset" size 100.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_prepare_two_webdav_dirs.sh"><code>kali_prepare_two_webdav_dirs.sh</code></a> <em>Create two WebDAV windows using Kali and tmuxp.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/mount_yoga_webdav_dir.sh"><code>mount_yoga_webdav_dir.sh</code></a> <em>Mount Yoga WebDAV Directories Script</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/utm_test_video_record.sh"><code>utm_test_video_record.sh</code></a> <em>Capture Ubuntu QEMU UTM ARM screens in MP4.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/webdav_macos_start.sh"><code>webdav_macos_start.sh</code></a> <em>Start WebDAV script on MacOS.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/vnc_unix_domain_socket.py"><code>vnc_unix_domain_socket.py</code></a> <em>Creates Unix socket, prints Twisted attributes.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_prepare_two_webdav_dirs.yaml"><code>kali_prepare_two_webdav_dirs.yaml</code></a> <em>Set up two WebDAV directories, read and read-write access.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/audio_record.py"><code>audio_record.py</code></a> <em>Records and saves audio with error handling.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/main_recorder.py"><code>main_recorder.py</code></a> <em>Manages recording of audio, video, HID with Redis signaling.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/record_audio_pulseaudio.sh"><code>record_audio_pulseaudio.sh</code></a> <em>Script records and saves pulseaudio audio streams as Opus files.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/main_loop.sh"><code>main_loop.sh</code></a> <em>Kills &amp; restarts Python processes in infinite loop, requires sudo.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/start_main_loop.sh"><code>start_main_loop.sh</code></a> <em>Starts Redis, kills Python processes, runs main_loop.sh (no log)</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/README.md"><code>README.md</code></a> <em>Quick start guide for Ubuntu QEMU UTM ARM recording setup.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/video_record.py"><code>video_record.py</code></a> <em>Script records screen with ffmpeg.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/prepare_workspace.sh"><code>prepare_workspace.sh</code></a> <em>Prepare workspace, link directories.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/random_actor_redis.py"><code>random_actor_redis.py</code></a> <em>Python tool for random GUI interactions, error handling, and Redis checks.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/macos_take_screenshot.py"><code>macos_take_screenshot.py</code></a> <em>Capture and save window screenshot.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/pyaudio_get_device_info.py"><code>pyaudio_get_device_info.py</code></a> <em>PyAudio, device list, prioritize BlackHole, channel check</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/launch_server.cmd"><code>launch_server.cmd</code></a> <em>Launch server command for Ubuntu QEMU UTM ARM WebDAV recording.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/macos_iterate_windows.sh"><code>macos_iterate_windows.sh</code></a> <em>Iterate window IDs, print or record.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/enable_audio_loopback.sh"><code>enable_audio_loopback.sh</code></a> <em>Enable audio loopback for Ubuntu ARM QEMU/UTM system.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_prepare_dirs_loop.sh"><code>kali_prepare_dirs_loop.sh</code></a> <em>Prepares Kali WebDAV directories for looping.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/test_util.py"><code>test_util.py</code></a> <em>Error from division by zero in test_util.py</em></li>
<li><strong><code>kali_vbox_control</code></strong> <em>Automated VM management and control.</em><ul>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/exec_vm_if_locked.py"><code>exec_vm_if_locked.py</code></a> <em>Lock, execute, unlock VM commands.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/modify_vm.sh"><code>modify_vm.sh</code></a> <em>Enable VRDE, set port for Ubuntu 16.04 VM.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/x11grab.py"><code>x11grab.py</code></a> <em>Captures screen from display 10 with X11 grabber</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/duplicate_frame_detector.py"><code>duplicate_frame_detector.py</code></a> <em>Detects locked VM screenshots.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/disable_logout_poweroff_button.sh"><code>disable_logout_poweroff_button.sh</code></a> <em>Suppresses logout, restart, and shutdown buttons.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/stop_on_ffmpeg_x11_error.py"><code>stop_on_ffmpeg_x11_error.py</code></a> <em>"Checks for Failed to query xcb pointer error, stops loop."</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/x11grab_loop_viewer.sh"><code>x11grab_loop_viewer.sh</code></a> <em>X11 grabbing script for FFplay from display 11.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/restore_vm.sh"><code>restore_vm.sh</code></a> <em>Restores snapshots of "Ubuntu 16.04" VM, except Snapshot 12.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/lightdm.conf"><code>lightdm.conf</code></a> <em>Set default user "hua", no timeout, Ubuntu session.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/exec_vm.sh"><code>exec_vm.sh</code></a> <em>Unlock session "c2", run /bin/loginctl for Ubuntu 16.04 guest with username hua, password 110110.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/start_vm.sh"><code>start_vm.sh</code></a> <em>Starts VirtualBox VM "Ubuntu 16.04"</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/control_vm.sh"><code>control_vm.sh</code></a> <em>Vbox: Stop audio, enable VRDE for Ubuntu 16.04 VM.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/kali_vbox_main_loop.py"><code>kali_vbox_main_loop.py</code></a> <em>Automated VM management and control.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/x11grab.sh"><code>x11grab.sh</code></a> <em>Capture X11 window content, save images, real-time playback.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/x11grab_loop.sh"><code>x11grab_loop.sh</code></a> <em>Xvfb server, x11grab.sh, X11 errors monitoring</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/xvfbwrapper_vboxmanager_test.py"><code>xvfbwrapper_vboxmanager_test.py</code></a> <em>Test script launches Ubuntu VM with Xvfb display and faulty progress bar.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/list_vm.sh"><code>list_vm.sh</code></a> <em>Lists all VMs in VirtualBox.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/xvfb_test_loop_double_display.py"><code>xvfb_test_loop_double_display.py</code></a> <em>Runs xvfb for display in virtual environment, loops "x11grab_loop.sh" script.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/the_frozen_forest.service"><code>the_frozen_forest.service</code></a> <em>The Frozen Forest dataset creation service.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/stop_vm.sh"><code>stop_vm.sh</code></a> <em>Stop VirtualBox VM and power off.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/check_vm.sh"><code>check_vm.sh</code></a> <em>Check Ubuntu 16.04 VirtualBox VM status</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/README.md"><code>README.md</code></a> <em>Automatic login, startup script, screenshots, systemd service creation.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/xvfb_test_loop_double_display.sh"><code>xvfb_test_loop_double_display.sh</code></a> <em>Xvfb double-display test script.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/kali_vbox_control/screenshot_vm.sh"><code>screenshot_vm.sh</code></a> <em>Take "Ubuntu 16.04" VM screenshot, save as output.png</em></li>
</ul>
</li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/macos_utm_run_qemu.sh"><code>macos_utm_run_qemu.sh</code></a> <em>Run UTM with QEMU, ARM image, Spice protocol, network config.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/utils.py"><code>utils.py</code></a> <em>Utils for Redis recordings and control in Ubuntu QEMU with ARM architecture.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/requirements.txt"><code>requirements.txt</code></a> <em>Required Python packages for project: redis, jsonlines, pynput.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/mouse_keyboard_record.py"><code>mouse_keyboard_record.py</code></a> <em>Pyautogui records HID events in Redis.</em></li>
<li><strong><code>test_record</code></strong><ul>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/test_record/video_record_script.sh"><code>video_record_script.sh</code></a> <em>Record 1920x1080 video with ffmpeg and python.</em></li>
</ul>
</li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/pyscreenshot_output.py"><code>pyscreenshot_output.py</code></a> <em>Capture screenshots, save, check Redis status.</em></li>
<li><a href="index.html?q=/ubuntu_qemu_utm_arm_record/mount_kali_webdav_dirs.sh"><code>mount_kali_webdav_dirs.sh</code></a> <em>Mount, configure, and symlink WebDAV directories.</em></li>
</ul>
</li>
<li><a href="index.html?q=/array_shape_typecheck.py"><code>array_shape_typecheck.py</code></a> <em>2D array, Array class, numpy, Literal casting, Jinja2 macros.</em></li>
<li><a href="index.html?q=/decorator_method_registry.py"><code>decorator_method_registry.py</code></a> <em>Decorator method registry: pre/post execution code.</em></li>
<li><a href="index.html?q=/pyright_utils.py"><code>pyright_utils.py</code></a> <em>Pyright utils: track errors, regex pattern, cache, undefined vars.</em></li>
<li><strong><code>test</code></strong> <em>Test directory with model training, abstract implementation, and error testing.</em><ul>
<li><a href="index.html?q=/test/run_test.sh"><code>run_test.sh</code></a> <em>Run test_project.py with pytest in parent folder</em></li>
<li><a href="index.html?q=/test/test_abstract_impl.py"><code>test_abstract_impl.py</code></a> <em>Abstract base class implementation with instantiation error.</em></li>
<li><a href="index.html?q=/test/test_project.py"><code>test_project.py</code></a> <em>Trains custom models with hypothesis strategies, Adam optimizer.</em></li>
</ul>
</li>
<li><strong><code>software_capture_hid_control</code></strong> <em>Controls software with HID and X11 streaming, abstract class tests.</em><ul>
<li><a href="index.html?q=/software_capture_hid_control/abstract_class_test.py"><code>abstract_class_test.py</code></a> <em>Abstract class with two abstract methods.</em></li>
<li><a href="index.html?q=/software_capture_hid_control/test_xdo.py"><code>test_xdo.py</code></a> <em>Tests HID control for software.</em></li>
<li><a href="index.html?q=/software_capture_hid_control/test_control.py"><code>test_control.py</code></a> <em>Control software with libxdoHID and X11 live streaming, saving image issues.</em></li>
<li><a href="index.html?q=/software_capture_hid_control/Makefile"><code>Makefile</code></a> <em>Builds and executes "test_control.py" with Makefile</em></li>
</ul>
</li>
<li><a href="index.html?q=/screenshot_test.py"><code>screenshot_test.py</code></a> <em>Screenshot testing in 0.03s</em></li>
<li><a href="index.html?q=/launch_docker_devicemapper_limit_storage.sh"><code>launch_docker_devicemapper_limit_storage.sh</code></a> <em>Docker storage options: devicemapper, limits explained.</em></li>
<li><strong><code>metalearning_random_shuffle</code></strong> <em>Shuffling datasets, reducing entropy for metalearning.</em><ul>
<li><a href="index.html?q=/metalearning_random_shuffle/README.md"><code>README.md</code></a> <em>Perform ops without annotations, reduce entropy.</em></li>
<li><a href="index.html?q=/metalearning_random_shuffle/main.py"><code>main.py</code></a> <em>Shuffling datasets with letter-digit combos</em></li>
</ul>
</li>
<li><strong><code>rt_x_experiments</code></strong> <em>Real-time RTX experimentation, diverse techniques and models.</em><ul>
<li><strong><code>rt_x_test_code</code></strong> <em>Efficient RTX model training with action interpretation and DirectML fix</em><ul>
<li><a href="index.html?q=/rt_x_experiments/rt_x_test_code/requirements.txt"><code>requirements.txt</code></a> <em>Lists: PyTorch libraries
Classifier-Free and EfficientNet</em></li>
<li><a href="index.html?q=/rt_x_experiments/rt_x_test_code/rtx1_example.py"><code>rtx1_example.py</code></a> <em>RTX1 model, random video data, computes train and eval logits.</em></li>
<li><a href="index.html?q=/rt_x_experiments/rt_x_test_code/rtx2_example.py"><code>rtx2_example.py</code></a> <em>Efficient model training with action interpretation and DirectML fix on RTX2.</em></li>
</ul>
</li>
<li><a href="index.html?q=/rt_x_experiments/zoom_pan_action.py"><code>zoom_pan_action.py</code></a> <em>Image cropping code with XY zoom-pan support.</em></li>
<li><strong><code>real_attention</code></strong> <em>Real-time attention experiments for image cropping and analysis.</em><ul>
<li><a href="index.html?q=/rt_x_experiments/real_attention/recursive_positional_encoding.py"><code>recursive_positional_encoding.py</code></a> <em>Recursive positional encoding for zoomed patches.</em></li>
<li><a href="index.html?q=/rt_x_experiments/real_attention/sin_2d_positional_encoding.py"><code>sin_2d_positional_encoding.py</code></a> <em>Bilinear interpolation for positional encoding visualization.</em></li>
<li><a href="index.html?q=/rt_x_experiments/real_attention/low_rank_positional_encoding.py"><code>low_rank_positional_encoding.py</code></a> <em>Low-rank positional encoding for attention models.</em></li>
<li><a href="index.html?q=/rt_x_experiments/real_attention/test_model_level_real_attention.py"><code>test_model_level_real_attention.py</code></a> <em>Image cropping functions with grayscale analysis and positional embedding exploration.</em></li>
<li><a href="index.html?q=/rt_x_experiments/real_attention/2d_convolve.py"><code>2d_convolve.py</code></a> <em>2D image convolution with scipy's convolve2d</em></li>
</ul>
</li>
<li><strong><code>fourier_transform_combine_data</code></strong> <em>Fourier transform experiments: 1D and 2D FFT, array combination, inverse.</em><ul>
<li><a href="index.html?q=/rt_x_experiments/fourier_transform_combine_data/test_multidimension_fourier_transform_2d.py"><code>test_multidimension_fourier_transform_2d.py</code></a> <em>2D FFT, combines arrays, inverse FFT, prints results</em></li>
<li><a href="index.html?q=/rt_x_experiments/fourier_transform_combine_data/test_fft_1d.py"><code>test_fft_1d.py</code></a> <em>Compute 1D FFT, combine, and inverse. Print results.</em></li>
<li><a href="index.html?q=/rt_x_experiments/fourier_transform_combine_data/test_common.py"><code>test_common.py</code></a> <em>Test script for array addition and print.</em></li>
</ul>
</li>
<li><strong><code>audio_to_mel</code></strong><ul>
<li><a href="index.html?q=/rt_x_experiments/audio_to_mel/test_librosa.py"><code>test_librosa.py</code></a> <em>Load audio, set sample rate, generate mel spectrogram, convert to dB, save as variable.</em></li>
</ul>
</li>
<li><strong><code>gradient_undescent</code></strong> <em>Dynamic learning rate optimization, unlearning with loss inversion and Adam optimizer experiments.</em><ul>
<li><a href="index.html?q=/rt_x_experiments/gradient_undescent/dynamic_learning_rate.py"><code>dynamic_learning_rate.py</code></a> <em>Dynamic learning rate optimization functions</em></li>
<li><a href="index.html?q=/rt_x_experiments/gradient_undescent/test_unlearning.py"><code>test_unlearning.py</code></a> <em>Unlearning model with loss inversion, Adam optimizer</em></li>
</ul>
</li>
<li><strong><code>special_tokenizer_with_actions</code></strong> <em>Special tokenizer for actions and text classification with optimization and hierarchical techniques.</em><ul>
<li><a href="index.html?q=/rt_x_experiments/special_tokenizer_with_actions/test_action_and_text_tokenizer.py"><code>test_action_and_text_tokenizer.py</code></a> <em>Custom tokenizer for actions and content, optimization techniques</em></li>
<li><a href="index.html?q=/rt_x_experiments/special_tokenizer_with_actions/test_hierachical_tokenization.py"><code>test_hierachical_tokenization.py</code></a> <em>Hierarchical tokenization model for text classification using Einops and sparse transforms.</em></li>
<li><a href="index.html?q=/rt_x_experiments/special_tokenizer_with_actions/test_tokenmonster.py"><code>test_tokenmonster.py</code></a> <em>TokenMonster vocab test.</em></li>
<li><a href="index.html?q=/rt_x_experiments/special_tokenizer_with_actions/hourglass_lm.py"><code>hourglass_lm.py</code></a> <em>Hourglass Transformer: Efficient Language Modeling</em></li>
<li><a href="index.html?q=/rt_x_experiments/special_tokenizer_with_actions/test_simutaneous_tokenization_embedding.py"><code>test_simutaneous_tokenization_embedding.py</code></a> <em>Concurrent embedding tokenization &amp; transformers for words and actions.</em></li>
</ul>
</li>
<li><a href="index.html?q=/rt_x_experiments/README.md"><code>README.md</code></a> <em>Dynamic tokenizer, attention layers, neuron states, activation functions, AI deviation.</em></li>
<li><strong><code>partial_training_network</code></strong><ul>
<li><a href="index.html?q=/rt_x_experiments/partial_training_network/test_freeze_one_and_train_another.py"><code>test_freeze_one_and_train_another.py</code></a> <em>Trains layers, manages RAM, controls GPU usage.</em></li>
</ul>
</li>
<li><a href="index.html?q=/rt_x_experiments/requirements.txt"><code>requirements.txt</code></a> <em>Package dependencies: rtx-torch, classifier-free-guidance-pytorch, efficientnet-pytorch</em></li>
</ul>
</li>
<li><a href="index.html?q=/autogui.py"><code>autogui.py</code></a> <em>AutoGUI Python script for GUI input capture and playback.</em></li>
<li><a href="index.html?q=/requirements.txt"><code>requirements.txt</code></a> <em>Data processing, image manipulation, keyboard handling libraries.</em></li>
<li><a href="index.html?q=/launch_streaming_utils.sh"><code>launch_streaming_utils.sh</code></a> <em>Launch script for streaming utilities in new tmux sessions.</em></li>
<li><a href="index.html?q=/keyboard_and_mouse.py"><code>keyboard_and_mouse.py</code></a> <em>Python script records keyboard and mouse events, configurable timesteps.</em></li>
<li><strong><code>usb_power_management</code></strong> <em>Optimize USB power management across Linux and Windows</em><ul>
<li><a href="index.html?q=/usb_power_management/README.md"><code>README.md</code></a> <em>Optimize USB power management for longevity.</em></li>
<li><strong><code>windows</code></strong><ul>
<li><a href="index.html?q=/usb_power_management/windows/README.md"><code>README.md</code></a> <em>USB device power management for Windows.</em></li>
</ul>
</li>
<li><strong><code>linux</code></strong> <em>Linux USB power management, solutions and scripts.</em><ul>
<li><a href="index.html?q=/usb_power_management/linux/README.md"><code>README.md</code></a> <em>Linux USB power management, solutions, and instructions</em></li>
<li><a href="index.html?q=/usb_power_management/linux/devcontrol.sh"><code>devcontrol.sh</code></a> <em>Activates USB power management, disables LPM.</em></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
    </article>
</body>

</html>